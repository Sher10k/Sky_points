if ((MySFM.good_points1.size() >= 8) && (MySFM.good_points2.size() >= 8))
                    { 
                        vector <Point2f> points1(MySFM.numKeypoints), points2(MySFM.numKeypoints), status(MySFM.numKeypoints);     // Point2f
                        cv::KeyPoint::convert(MySFM.good_points1, points1);     // Convert from KeyPoint to Point2f
                        cv::KeyPoint::convert(MySFM.good_points2, points2);
                        cv::Mat pnts3D(4, static_cast<int>(MySFM.numKeypoints), CV_64F);         // 3D points.  static_cast<int>(good_points1.size())
                        
                        vector <cv::Mat> points2frame(2);                       // Vector of key point arrays for each frame
                        points2frame[0] = cv::Mat(2, static_cast<int>(points1.size()), CV_64F);
                        points2frame[1] = cv::Mat(2, static_cast<int>(points2.size()), CV_64F);
                        
                        for (int i = 0; i < static_cast<int>(MySFM.numKeypoints); i++) {         // Unioning the key points in new variable
                            points2frame[0].at<float>(0, i) = points1[static_cast<unsigned long>(i)].x;
                            points2frame[0].at<float>(1, i) = points1[static_cast<unsigned long>(i)].y;
                            points2frame[1].at<float>(0, i) = points2[static_cast<unsigned long>(i)].x;
                            points2frame[1].at<float>(1, i) = points2[static_cast<unsigned long>(i)].y;
                            /*cout    << "points2frame [0](0, " << i << ") = " << points2frame[0].at<float>(0, i) << endl
                                    << "points2frame [0](1, " << i << ") = " << points2frame[0].at<float>(1, i) << endl
                                    << "points2frame [1](0, " << i << ") = " << points2frame[1].at<float>(0, i) << endl
                                    << "points2frame [1](1, " << i << ") = " << points2frame[1].at<float>(1, i) << endl
                                    << endl;*/
                        }
                        
                        // FindFundamentalMat     -------------------------------------------------------------//      step 4
                        sfm::reconstruct(points2frame, Ps, pnts3D, Calib.cameraMatrix, true);
                        /*cout    << "pnts3D.cols = " << pnts3D.cols
                                << endl;
                        for (int i = 0; i < pnts3D.cols; i++){
                            for (int j = 0; j < pnts3D.rows; j++){
                                cout << " " << pnts3D.at<double>(i, j) << " ";
                            }
                            cout << endl;
                        }
                            // 3D points cloud
                        //pcl::PointCloud <pcl::PointXYZ> cloud;
                        cloud.height = 1;
                        cloud.width = static_cast<unsigned int>( pnts3D.cols );
                        cloud.is_dense = false;
                        cloud.points.resize( cloud.width * cloud.height );
                        
                        for (size_t i = 0; i < cloud.points.size (); ++i)
                        {
                            cloud.points[i].x = pnts3D.at<float>(0, static_cast<int>(i));
                            cloud.points[i].y = pnts3D.at<float>(1, static_cast<int>(i));
                            cloud.points[i].z = pnts3D.at<float>(2, static_cast<int>(i));
                            //cloud.points[i].r = rgb_cenal[2].at(i);
                            //cloud.points[i].g = rgb_cenal[1].at(i);
                            //cloud.points[i].b = rgb_cenal[0].at(i);
                        }
                            // Save 3D points in file
                        pcl::io::savePCDFileASCII ("Reconstruct_cloud.pcd", cloud);
                            // Load 3D points (cloud points)
                        //pcl::PointCloud<pcl::PointXYZ>::Ptr cloud2 (new pcl::PointCloud<pcl::PointXYZ>);
                        pcl::io::loadPCDFile("Reconstruct_cloud.pcd", *cloud2);*/
                            // View cloud points
                        /*pcl::visualization::CloudViewer viewer("Cloud Viewer");
                        viewer.showCloud(cloud2, "cloud");*/
                        
                        // END FindFundamentalMat     ---------------------------------------------------------//    END step 4
                        
                        /*fundamental_matrix = cv::findFundamentalMat(points1, points2, FM_RANSAC, 1.0, 0.99, noArray());
                        if (!fundamental_matrix.empty()) {  // Проверка на пустотности фундаментальной матрицы
                            
//                                projectionsFromFundamental(fundamental_matrix, Pt1, Pt2);
//                                Ps[0] = Pt1;
//                                Ps[1] = Pt2;
                            
                            //cv::sfm::triangulatePoints(points2frame, Ps, pnts3D);                 // Triangulate and find 3D points using inliers, with SFM
                            //cv::triangulatePoints(Pt1, Pt2, point_good1, point_good2, pnts3D);    // Triangulation without SFM
//                                cout    << "pnts3D.cols = " << pnts3D.cols
//                                        << endl;
//                                for (int i = 0; i < pnts3D.cols; i++){
//                                    for (int j = 0; j < pnts3D.rows; j++){
//                                        cout << " " << pnts3D.at<double>(i, j) << " ";
//                                    }
//                                    cout << endl;
//                                }
//                                FileStorage poins3D;      // Вывод в файл 3д точек
//                                poins3D.open("poins3D_XYZ.txt", FileStorage::WRITE);
//                                poins3D << "pnts3D" << pnts3D;
//                                poins3D.release();
                            
                            cv::computeCorrespondEpilines(points1, 1 , fundamental_matrix, lines[0]);   // Расчет эпиполярных линый для 1го кадра
                            cv::computeCorrespondEpilines(points2, 2 , fundamental_matrix, lines[1]);   // Расчет эпиполярных линый для 2го кадра
                            
                            frame.copyTo( frame_epipol1 );
                            frame2.copyTo( frame_epipol2 );
                            //drawlines(frame_epipol1, lines[0], points1);  // Отрисовка эпиполярных линий
                            //drawlines(frame_epipol2, lines[1], points2);
                            
//                                Rect r1(0, 0, frame_epipol1.cols, frame_epipol1.rows);                // Создаем фрагменты для склеивания зображения
//                                Rect r2(frame_epipol2.cols, 0, frame_epipol2.cols, frame_epipol2.rows);
//                                frame_epipol1.copyTo(frame4( r1 ));
//                                frame_epipol2.copyTo(frame4( r2 ));
//                                imshow("1-2 frame", frame4);

                            drawMatches(frame_epipol1, good_points1, frame_epipol2, good_points2, good_matches, frame4);
                            imshow("1-2 frame", frame4);
                        }*/
                        
                        drawMatches(MySFM.frame1, MySFM.good_points1, MySFM.frame2, MySFM.good_points2, MySFM.good_matches, MySFM.frame4);
                        imshow("1-2 frame", MySFM.frame4);
                    } else {
                        // Вывод первого кадра и пустого кадра
                        MySFM.frame2 *= 0;
                        Rect r1(0, 0, MySFM.frame1.cols, MySFM.frame1.rows);
                        Rect r2(MySFM.frame2.cols, 0, MySFM.frame2.cols, MySFM.frame2.rows);
                        MySFM.frame1.copyTo(MySFM.frame4( r1 ));
                        MySFM.frame2.copyTo(MySFM.frame4( r2 ));
                        imshow("1-2 frame", MySFM.frame4);
                    }










// SURF Find matches between points
unsigned long Match_find_SURF(vector<KeyPoint> kpf1,
                              vector<KeyPoint> kpf2,
                              Mat dpf1,
                              Mat dpf2,
                              vector<KeyPoint> *gp1,
                              vector<KeyPoint> *gp2,
                              vector<DMatch> *gm,
                              unsigned long kn)
{
    Ptr<DescriptorMatcher> matcher = DescriptorMatcher::create(DescriptorMatcher::BRUTEFORCE);
    vector<DMatch> matches;
    DMatch dist1, dist2;

    //matcher.match(dpf1, dpf2, matches, noArray());   // Matches key points of the frame with key points of the frame2
    matcher->match(dpf1, dpf2, matches, noArray());

    // Sort match
    unsigned long temp = 0;
    kn = static_cast<unsigned long>(matches.size());
    for (unsigned long i = 0; i < kn - 1; i++) { //key_num - 1
        dist1 = matches[i];
        for (unsigned long j = i + 1; j < kn; j++) {
            dist2 = matches[j];
            if (dist2.distance < dist1.distance) {
                dist1 = matches[j];
                temp = j;
            }
            if (j == kn - 1) {
                matches[temp] = matches[i];
                matches[i] = dist1;
                break;
            }
        }
    }
    //-- Вычисление максимального и минимального расстояния среди всех дескрипторов в пространстве признаков
    float max_dist = 0, min_dist = 100;
    for(size_t i = 0; i < matches.size(); i++ ) {
        float dist = matches[i].distance;
        if( dist < min_dist ) min_dist = dist;
        if( dist > max_dist ) max_dist = dist;
    }
    cout << "-- Max dist : " << max_dist << endl;
    cout << "-- Min dist : " << min_dist << endl;
    // Selection of key points on both frames satisfying the threshold
    temp = 0;
    for (size_t i = 0; i < matches.size(); i++) {
        if (matches[i].distance <  3*min_dist) { // threshold
            int new_i = static_cast<int>( gp1->size() );
            gp1->push_back( kpf1[ static_cast<unsigned long>( matches[i].queryIdx ) ] );
            gp2->push_back( kpf2[ static_cast<unsigned long>( matches[i].trainIdx ) ] );
            gm->push_back( DMatch(new_i, new_i, 0) );
            temp++;
        }
    }
    cout << "-- Temp : " << temp << endl << endl;
    return temp;
}








if ( (f == 1) && (mode_cam == true) ) {         // Основной режим работы камеры, потоковый режим, !viewer->wasStopped ()
            //  Wait for a new frame from camera and store it into 'frameImg'
            if (!cap.read(frameImg)) { // check if we succeeded
                cerr << "ERROR! blank frame grabbed\n";
                break;
            }
            undistort(frameImg, frame, Calib.cameraMatrix, Calib.distCoeffs);

            // Delay frame2         ------------------------------------------------------------//
            /*frame_MSEC = cap.get(CAP_PROP_POS_MSEC);
            frame_MSEC2 = cap.get(CAP_PROP_POS_MSEC);
            while((frame_MSEC2 - frame_MSEC) < frame_pause)
            {
                cap.read(frame2);
                frame_MSEC2 = cap.get(CAP_PROP_POS_MSEC);
                //cout  <<    "MSEC = " << cap.get(CAP_PROP_POS_MSEC) << endl;
            }
            //cout << "//---------------------------  = " << frame_pause <<endl;*/
            // End Delay frame2         --------------------------------------------------------//

            // Находим оптимальное преобразование, 
            // согласующееся с большинством пар точек. 
            /*vector<Point2f> pt1, pt2; 
            for( size_t i = 0; i < matches.size(); i++ ) { 
             pt1.push_back(keypoints1[matches[i].queryIdx].pt); 
             pt2.push_back(keypoints2[matches[i].trainIdx].pt); 
            } 
            // H – это матрица оптимального перспективного 
            // преобразования от img1 к img2 
            Mat H = findHomography(pt1, pt2, RANSAC, 10); */
            
            // ORB detector        -------------------------------------------------------------//      step 1
            if (!cap.read(frameImg2)) { // check if we succeeded and store new frame into 'frameImg2'
                cerr << "ERROR! blank frame grabbed\n";
                break;
            }
            undistort(frameImg2, frame2, Calib.cameraMatrix, Calib.distCoeffs);
            
            detector->detectAndCompute(frame, noArray(), keypoints_frame, descriptors_frame);       // Detected key points at frame
            detector->detectAndCompute(frame2, noArray(), keypoints_frame2, descriptors_frame2);    // Detected key points at frame2

            if ((keypoints_frame.size() != 0) && (keypoints_frame2.size() != 0)) {          // Проверка на нахождение хотябы одной контрольной точки
                
                vector<DMatch> good_matches;
                vector<KeyPoint> good_points1, good_points2;
                t = Match_find( keypoints_frame,
                                keypoints_frame2,
                                descriptors_frame,
                                descriptors_frame2,
                                &good_points1,
                                &good_points2,
                                &good_matches,
                                key_num,
                                20 );                                                  // Поиск схожих точек удовлетворяющих порогу
                
                // drawing two frames and connecting similar cue points with lines
                drawMatches(frame, good_points1, frame2, good_points2, good_matches, res);
            // END ORB detector        ------------------------------------------------------------//   END step 1
                
                if ((good_points1.size() >= 8) && (good_points2.size() >= 8)) { // Проверка на наличие точек, удовлетворяющих порогу
                    // FindFundamentalMat     -------------------------------------------------------------//      step 2
                    vector<Point2f> points1(t);
                    vector<Point2f> points2(t);
                    vector<Point2f> status(t);
                    
                    for (unsigned long i = 0; i < t; i++) {
                        points1[i].x = good_points1[i].pt.x;
                        points1[i].y = good_points1[i].pt.y;
                        points2[i].x = good_points2[i].pt.x;
                        points2[i].y = good_points2[i].pt.y;
                    }
                    fundamental_matrix = cv::findFundamentalMat(points1, points2, FM_RANSAC, 1.0, 0.99, noArray());
                    /*for(int i = 0; i < fundamental_matrix.rows; i++){     // Отображение элементов 
                        for(int j = 0; j < fundamental_matrix.cols; j++){
                            //printf("fundamental_matrix[%.0f ", ptr[j]);
                            printf("fundamental_matrix [ %i ][ %i ] = %5.7f\n", i, j, fundamental_matrix.at<double>(j,i));
                        }
                        //printf("\n");
                    }
                    //printf("-----\n");*/
                    // END FindFundamentalMat     ---------------------------------------------------------//   END step 2
                    
                    if (!fundamental_matrix.empty()) {  // Draw epilines between two image     -------------//      step 3
                        
                        cv::computeCorrespondEpilines(points1, 1 , fundamental_matrix, lines[0]);
                        cv::computeCorrespondEpilines(points2, 2 , fundamental_matrix, lines[1]);
                                                
                        drawlines(frame, lines[0], points1);
                        drawlines(frame2, lines[1], points2);
                                           
                        Rect r1(0, 0, frame.cols, frame.rows);                // Создаем фрагменты для склеивания зображения
                        Rect r2(frame2.cols, 0, frame2.cols, frame2.rows);
                        frame.copyTo(frame4( r1 ));
                        frame2.copyTo(frame4( r2 ));                    
                        imshow("frame_epipol_double", frame4);
                        
                    }   // END Draw epilines between two image  ---------------------------------------------//   END step 3
                } else {
                    frame4 = res;
                    imshow("frame_epipol_double", frame4);
                }
            } else {                                                                 // if points not found
                Rect r1(0, 0, frame.cols, frame.rows);                
                Rect r2(frame2.cols, 0, frame2.cols, frame2.rows);
                frame.copyTo(frame4( r1 ));
                frame2.copyTo(frame4( r2 )); 
                imshow("frame_epipol_double", frame4);
            }

            // Farneback optical flow -------------------------------------------------------------//      step #
            /*cap.read(frame2);
            frame2.copyTo(img2Original);
            cvtColor(frame, frame, COLOR_BGR2GRAY);
            cvtColor(frame2, frame2, COLOR_BGR2GRAY);
            calcOpticalFlowFarneback(frame, frame2, flow, 0.4, 1, 12, 2, 8, 1.2, 0);
            //calcOpticalFlowSparseToDense();
            for (int y = 0; y < frame2.rows; y += 3) {
                for (int x = 0; x < frame2.cols; x += 3) {
                    // get the flow from y, x position * 3 for better visibility
                    const Point2f flowatxy = flow.at<Point2f>(y, x) * 1;
                    // draw line at flow direction
                    line(img2Original, Point(x, y), Point(cvRound(x + flowatxy.x), cvRound(y + flowatxy.y)), Scalar(255, 0, 0));
                    // draw initial point
                    circle(img2Original, Point(x, y), 1, Scalar(0, 0, 0), -1);
                }
            }
            //imshow("frame", frame);
            //imshow("frame2", frame2);
            imshow("img2Original", img2Original);*/
            // End Farneback optical flow ---------------------------------------------------------//


            //  Harris corner detector      -------------------------------------------------------//
            /*int blockSize = 2;
            int apertureSize = 3;
            double k = 0.04;
            //cvtColor(frame, frame_grey, COLOR_BGR2GRAY);
            Canny(frame, frame_grey, 100, 100, 3, false);
            Mat dst = Mat::zeros( frame.size(), CV_32FC1 );
            cornerHarris( frame_grey, dst, blockSize, apertureSize, k, BORDER_DEFAULT);
            Mat dst_norm, dst_norm_scaled;
            normalize( dst, dst_norm, 0, 255, NORM_MINMAX, CV_32FC1, Mat() );
            convertScaleAbs( dst_norm, dst_norm_scaled );
            for( int i = 0; i < dst_norm.rows ; i++ )
            {
                for( int j = 0; j < dst_norm.cols; j++ )
                {
                    if( (int) dst_norm.at<float>(i,j) > thresh )
                    {
                        //circle( dst_norm_scaled, Point(j,i), 1,  Scalar(255), -1, LINE_4, 0 );
                        circle( frame, Point(j,i), 5,  Scalar(0), 2, 8, 0 );
                    }
                }
            }
            imshow("frame", frame);
            imshow("frame_grey", frame_grey);
            //imshow("dst", dst);
            //imshow("dst_norm", dst_norm);
            //imshow("dst_norm_scaled", dst_norm_scaled);*/
            //  End Harris corner detector      ----------------------------------------------------//


            //double K = 0.4;
            //resize(frame, frame, Size(), K, K, CV_INTER_LINEAR);    //  Resize   -----------------//

            //imshow("Frame_live", frame);
            //cout  <<    "MSEC = " << cap.get(CAP_PROP_POS_MSEC) << endl;
        } 
